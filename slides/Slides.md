---
marp: true
title: Orchestrierung von Open-Data-Aktualisierungen mit Apache Airflow
author: Alexander G√ºntert
paginate: true
theme: weber
---

<!-- _class: titlepage -->
# Orchestrierung Open-Data-Aktualisierungen mit Apache Airflow
## CAS Data Engineering HS25
### Use Case Pr√§sentation 
#### Alexander G√ºntert

[üëâ Folien als PDF herunterladen](/Slides.pdf)

<style>
.bottom-img-row {
  display: flex;
  justify-content: right;
  align-items: center;
  gap: 24px;            
  margin-top: 24px;
}
.bottom-img {
  height: 100px;
}
</style>
<div class="bottom-img-row">
  <img class="bottom-img" src="https://upload.wikimedia.org/wikipedia/commons/7/71/AirflowLogo.svg" />
  <img class="bottom-img" src="https://data.stadt-zuerich.ch/logo.svg" />
</div>


---

# Warum jetzt?

- Open Data Z√ºrich betreibt **zahlreiche historisch gewachsene Aktualisierungsprozesse** √ºber unterschiedliche Kan√§le:
  - üì• Dropzone (WebDAV Harvester)
  - ü§ñ GitHub Actions
  - ü¶ä GitLab Pipelines
  - ‚è∞ CRON-Jobs
  - üì§ Manuelle Uploads
- **Zunehmende Anzahl und Komplexit√§t** der Datens√§tze
- H√∂here Anforderungen an Zuverl√§ssigkeit, Monitoring und Nachvollziehbarkeit

‚û°Ô∏è Jetzt ist der richtige Zeitpunkt f√ºr eine **Standardisierung und Zentralisierung**

---

# Was passiert, wenn wir nichts tun?

**Pain (Ist-Zustand):**
- Kein zentrales Monitoring
- Fehler werden oft  sp√§t erkannt
- Unterschiedliche Metadatenverarbeitung je nach Kanal
- Kein automatisches Retry bei tempor√§ren API-Fehlern
- Gesamte Prozesse m√ºssen bei Fehlern neu gestartet werden

**Erwarteter Win:**
- Weniger manuelle Eingriffe
- Schnellere Fehlerbehebung
- H√∂here Stabilit√§t und Transparenz

---

# Welches Problem l√∂sen wir?

- Fehlende **zentrale Orchestrierung** aller Datenaktualisierungen
- Keine einheitliche:
  - √úberwachung
  - Fehlerbehandlung
  - Wiederholbarkeit
- Abh√§ngigkeit von **externen Services** (z. B. GitHub Actions)

‚û°Ô∏è Ziel: **Einheitlicher, robuster und skalierbarer Aktualisierungsprozess**

---

# Wie sieht die L√∂sung aus?
      
**Apache Airflow als zentraler Orchestrator**

- Steuerung aller Aktualisierungen √ºber DAGs
- Einheitliches Monitoring & Logging
- Konfigurierbare Retry-Mechanismen
- Klare Trennung:
  - Orchestrierung (Airflow)
  - Fachlogik (Docker-Container)

**Ergebnis:**
- Standardisierte Pipelines
- Bessere Wartbarkeit
- Zukunftssichere Architektur

![bg right:38% h:48%](img/airflow_architektur.svg)

---

# Beispiel-Pipeline: Inventar Hauptarchiv Stadtarchiv Z√ºrich

**Warum dieser Use Case?**
- Typischer Open-Data-Aktualisierungsprozess
- Hohe Komplexit√§t (API-Abfrage (SRU), PDF-Downloads, KI-basierte Textzusammenfassungen, CSV & Parquet, Metadaten-Update in CKAN)

‚û°Ô∏è Ideal als **Blaupause f√ºr weitere Pipelines**

![bg right:40% h:90%](img/mermaid_download_sru.svg)

---


# Technische Umsetzung (POC)

- Eigener Airflow-DAG f√ºr den Use Case
- Verarbeitungsschritte als Docker-Container in separatem [Repository](https://github.com/alexanderguentert/cas-de-airflow-container)
- Gemeinsames Volume f√ºr Datenaustausch
- Parallelisierung einzelner Tasks (z. B. CSV & Parquet Upload)

**Technologien:**
- Apache Airflow
- Python
- Docker Operator
- CKAN API
- Google Gemini API (f√ºr Zusammenfassungen)

---

# Was wurde bereits umgesetzt?

- Vollst√§ndiger **Proof of Concept**
- Ein funktionsf√§higer Airflow-DAG
- Erfolgreiche Aktualisierung:
  - Daten (CSV & Parquet)
  - Metadaten im CKAN
- Dokumentation & reproduzierbares Setup auf [Github](https://github.com/alexanderguentert/cas-de-airflow/)

‚û°Ô∏è L√∂sung ist **demonstrierbar und erweiterbar**

![bg right:45% h:100%](img/screenshot_dag.png)

---

# Mehrwert der L√∂sung

- Zusammenf√ºhrung aller Datenaktualisierungen in einerm Tool
- Zentrales Monitoring
- Einheitliche Metadatenverarbeitung
- Retries oder Teilwiederholungen bei Fehlern
- Unabh√§ngigkeit von Github Actions / Gitlab Pipelines m√∂glich (aber nicht notwendig)

‚û°Ô∏è **Robuste Basis f√ºr zuk√ºnftige Open-Data-Prozesse**

---

# Call-to-Action

**N√§chste Schritte:**
- Vorstellung bei stadtinternen Stakeholdern
- Einbindung in SSZ-Toolstack pr√ºfen
- Testdeployment des PoC auf st√§dtischer CMP
- Definition eines Standard-DAG-Templates
- Einbindung zus√§tzlicher Datenquellen (Externe APIs, Filesysteme)
- **Perspektivisch:**
  - Integration des st√§dtischen Metadatenkatalogs (SDK)
  - Integration DWH

![bg right:35% h:100%](img/ChatGPT_rocket.png)
<figcaption align="right">
<b>Bildquelle</b>: ChatGPT
</figcaption>
